svd_u_1 <- tiltedCCA::generate_sbm_orthogonal(B_mat1, membership_vec, centered = T)[,1:2]
svd_u_2 <- tiltedCCA::generate_random_orthogonal(n, 2, centered = T)
p_1 <- p1; p_2 <- p2
svd_d_1 <- sqrt(n*p_1)*c(1.5,1); svd_d_2 <- sqrt(n*p_2)*c(1.5,1)
svd_v_1 <- tiltedCCA::generate_random_orthogonal(p_1, 2)
svd_v_2 <- tiltedCCA::generate_random_orthogonal(p_2, 2)
mat_1 <- tcrossprod(svd_u_1 %*% diag(svd_d_1), svd_v_1) + matrix(rnorm(n*p_1, 0, 1), n, p_1)
mat_2 <- tcrossprod(svd_u_2 %*% diag(svd_d_2), svd_v_2) + matrix(rnorm(n*p_2, 0, 1), n, p_2)
clustering_1 <- factor(stats::kmeans(mat_1, centers = 3)$cluster)
clustering_2 <- factor(rep(1, length(membership_vec)))
rownames(mat_1) <- paste0("n", 1:nrow(mat_1))
rownames(mat_2) <- paste0("n", 1:nrow(mat_2))
colnames(mat_1) <- paste0("g", 1:ncol(mat_1))
colnames(mat_2) <- paste0("p", 1:ncol(mat_2))
return(list(mat_1, mat_2, true_cluster))
sim2 <- function(n, p1, p2){ #Lin simulation 1
n_clust <- n/3
B_mat1 <- matrix(c(0.9, 0.1, 0.1,
0.1, 0.9, 0.1,
0.1, 0.1, 0.9), 3, 3, byrow = T)
K <- ncol(B_mat1)
membership_vec <- c(rep(1, n_clust), rep(2, n_clust), rep(3, n_clust))
true_cluster <- c(rep(1, n_clust), rep(2, n_clust), rep(3, n_clust))
n <- length(membership_vec); true_membership_vec <- membership_vec
svd_u_1 <- tiltedCCA::generate_sbm_orthogonal(B_mat1, membership_vec, centered = T)[,1:2]
svd_u_2 <- tiltedCCA::generate_random_orthogonal(n, 2, centered = T)
p_1 <- p1; p_2 <- p2
svd_d_1 <- sqrt(n*p_1)*c(1.5,1); svd_d_2 <- sqrt(n*p_2)*c(1.5,1)
svd_v_1 <- tiltedCCA::generate_random_orthogonal(p_1, 2)
svd_v_2 <- tiltedCCA::generate_random_orthogonal(p_2, 2)
mat_1 <- tcrossprod(svd_u_1 %*% diag(svd_d_1), svd_v_1) + matrix(rnorm(n*p_1, 0, 1), n, p_1)
mat_2 <- tcrossprod(svd_u_2 %*% diag(svd_d_2), svd_v_2) + matrix(rnorm(n*p_2, 0, 1), n, p_2)
clustering_1 <- factor(stats::kmeans(mat_1, centers = 3)$cluster)
clustering_2 <- factor(rep(1, length(membership_vec)))
rownames(mat_1) <- paste0("n", 1:nrow(mat_1))
rownames(mat_2) <- paste0("n", 1:nrow(mat_2))
colnames(mat_1) <- paste0("g", 1:ncol(mat_1))
colnames(mat_2) <- paste0("p", 1:ncol(mat_2))
return(list(mat_1, mat_2, true_cluster))
}
sim2(n, 100, 100)
B_mat1
membership_vec <- c(rep(1, n_clust), rep(2, n_clust), rep(3, n_clust))
true_cluster <- c(rep(1, n_clust), rep(2, n_clust), rep(3, n_clust))
n <- length(membership_vec);
return(list(X1 = mat_1, X2=mat_2, clusters = true_cluster))
n =1000
p=c(100, 100, 100)
K=3
sd = 0.3
max_number_modalities_per_cluster=2
### Example: test <- simulation_cluster_model(1000, p=c(100, 100, 100), K=3, sd = 0.3, max_number_modalities_per_cluster=2)
views <- length(p)
if (K > choose(views, max_number_modalities_per_cluster)){
print("Error: chose too many clusters")
return()
}
K
start_index <- cumsum(c(1, p))[1:views]
stop_index <- cumsum(p)
mu <- matrix(rnorm(K * views, 0, 10),
views, K)
mu
sum_p = sum(p)
loadings <- matrix(0, sum_p, ncol=K)
GT_participation <- list()
for (k in 1:K){
### select subset of modalities to be involved in the cluster
subset_modalities = sort(sample(1:views, size=max_number_modalities_per_cluster))
#print(c(k, subset_modalities))
is_in_list <- any(sapply(GT_participation, function(x) all(x == subset_modalities)))
while(is_in_list){
#print("here")
subset_modalities = sort(sample(1:views, size=max_number_modalities_per_cluster))
is_in_list <- any(sapply(GT_participation, function(x) all(x == subset_modalities)))
}
GT_participation[[k]] <- subset_modalities
for (m in subset_modalities){
loadings[start_index[m]: stop_index[m],k] = rnorm(n=p[m], mean=mu[m, k], sd=0.1)
}
}
score = matrix(0, nrow=K, ncol=n)
cluster = sapply(1:n, function(x){sample(1:K, 1)})
score[cbind(cluster, 1:n)] <- 1
means <- t(loadings %*% score)
# Generate mat_1 with random values from a normal distribution
mat <- matrix(rnorm(length(means),
mean = as.vector(means), sd = sd),
nrow = n,
ncol = sum_p)
start_index <- cumsum(c(1, p))[1:views]
stop_index <- cumsum(p)
mu <- matrix(rnorm(K * views, 0, 10),
views, K)
matrix
mu
mu <- matrix(rnorm(K * views, 2, 10),
views, K)
mu
sum_p = sum(p)
loadings <- matrix(0, sum_p, ncol=K)
loadings
### select subset of modalities to be involved in the cluster
subset_modalities = sort(sample(1:views, size=max_number_modalities_per_cluster))
#print(c(k, subset_modalities))
is_in_list <- any(sapply(GT_participation, function(x) all(x == subset_modalities)))
is_in_list
GT_participation
### Example: test <- simulation_cluster_model(1000, p=c(100, 100, 100), K=3, sd = 0.3, max_number_modalities_per_cluster=2)
views <- length(p)
if (K > choose(views, max_number_modalities_per_cluster)){
print("Error: chose too many clusters")
return()
}
start_index <- cumsum(c(1, p))[1:views]
stop_index <- cumsum(p)
mu <- matrix(rnorm(K * views, 2, 10),
views, K)
sum_p = sum(p)
loadings <- matrix(0, sum_p, ncol=K)
GT_participation <- list()
GT_variables <- list()
for (k in 1:K){
### select subset of modalities to be involved in the cluster
subset_modalities = sort(sample(1:views, size=max_number_modalities_per_cluster))
#print(c(k, subset_modalities))
is_in_list <- any(sapply(GT_participation, function(x) all(x == subset_modalities)))
while(is_in_list){
#print("here")
subset_modalities = sort(sample(1:views, size=max_number_modalities_per_cluster))
is_in_list <- any(sapply(GT_participation, function(x) all(x == subset_modalities)))
}
GT_participation[[k]] <- subset_modalities
GT_variables[[k]] <- c()
for (m in subset_modalities){
if (is.null(s_m)){
loadings[start_index[m]: stop_index[m],k] = rnorm(n=p[m], mean=mu[m, k], sd=0.1)
GT_variables[[k]] <- c(GT_variables[[k]], start_index[m]: stop_index[m] )
}else{
index = sample(start_index[m]: stop_index[m], size=s_m, replace=FALSE)
GT_variables[[k]] <- c(GT_variables[[k]], index)
loadings[index,k] = rnorm(n=s_m, mean=mu[m, k], sd=0.1)
}
}
}
s_m=50
for (k in 1:K){
### select subset of modalities to be involved in the cluster
subset_modalities = sort(sample(1:views, size=max_number_modalities_per_cluster))
#print(c(k, subset_modalities))
is_in_list <- any(sapply(GT_participation, function(x) all(x == subset_modalities)))
while(is_in_list){
#print("here")
subset_modalities = sort(sample(1:views, size=max_number_modalities_per_cluster))
is_in_list <- any(sapply(GT_participation, function(x) all(x == subset_modalities)))
}
GT_participation[[k]] <- subset_modalities
GT_variables[[k]] <- c()
for (m in subset_modalities){
if (is.null(s_m)){
loadings[start_index[m]: stop_index[m],k] = rnorm(n=p[m], mean=mu[m, k], sd=0.1)
GT_variables[[k]] <- c(GT_variables[[k]], start_index[m]: stop_index[m] )
}else{
index = sample(start_index[m]: stop_index[m], size=s_m, replace=FALSE)
GT_variables[[k]] <- c(GT_variables[[k]], index)
loadings[index,k] = rnorm(n=s_m, mean=mu[m, k], sd=0.1)
}
}
}
K
k
sum_p = sum(p)
loadings <- matrix(0, sum_p, ncol=K)
GT_participation <- list()
GT_variables <- list()
### select subset of modalities to be involved in the cluster
subset_modalities = sort(sample(1:views, size=max_number_modalities_per_cluster))
subset_modalities
#print(c(k, subset_modalities))
is_in_list <- any(sapply(GT_participation, function(x) all(x == subset_modalities)))
is_in_list
while(is_in_list){
#print("here")
subset_modalities = sort(sample(1:views, size=max_number_modalities_per_cluster))
is_in_list <- any(sapply(GT_participation, function(x) all(x == subset_modalities)))
}
GT_participation[[k]] <- subset_modalities
GT_variables[[k]] <- c()
GT_variables
subset_modalities
m=2
index = sample(start_index[m]: stop_index[m], size=s_m, replace=FALSE)
index
p
GT_variables[[k]] <- c(GT_variables[[k]], index)
GT_variables[[k]]
GT_variables[[k]] <- list()
GT_variables[[k]] <- c(GT_variables[[k]], index)
loadings[index,k] = rnorm(n=s_m, mean=mu[m, k], sd=0.1)
sum_p = sum(p)
loadings <- matrix(0, sum_p, ncol=K)
GT_participation <- list()
GT_variables <- list()
for (k in 1:K){
### select subset of modalities to be involved in the cluster
subset_modalities = sort(sample(1:views, size=max_number_modalities_per_cluster))
#print(c(k, subset_modalities))
is_in_list <- any(sapply(GT_participation, function(x) all(x == subset_modalities)))
while(is_in_list){
#print("here")
subset_modalities = sort(sample(1:views, size=max_number_modalities_per_cluster))
is_in_list <- any(sapply(GT_participation, function(x) all(x == subset_modalities)))
}
GT_participation[[k]] <- subset_modalities
GT_variables[[k]] <- list()
for (m in subset_modalities){
if (is.null(s_m)){
loadings[start_index[m]: stop_index[m],k] = rnorm(n=p[m], mean=mu[m, k], sd=0.1)
GT_variables[[k]] <- c(GT_variables[[k]], start_index[m]: stop_index[m] )
}else{
index = sample(start_index[m]: stop_index[m], size=s_m, replace=FALSE)
GT_variables[[k]] <- c(GT_variables[[k]], index)
loadings[index,k] = rnorm(n=s_m, mean=mu[m, k], sd=0.1)
}
}
}
score = matrix(0, nrow=K, ncol=n)
cluster = sapply(1:n, function(x){sample(1:K, 1)})
score[cbind(cluster, 1:n)] <- 1
means <- t(loadings %*% score)
means
# Generate mat_1 with random values from a normal distribution
mat <- matrix(rnorm(length(means),
mean = as.vector(means), sd = sd),
nrow = n,
ncol = sum_p)
mat
clusters
cluster
just_joint = TRUE
max_number_modalities_per_cluster=2
### Example: test <- simulation_cluster_model(1000, p=c(100, 100, 100), K=3, sd = 0.3, max_number_modalities_per_cluster=2)
views <- length(p)
if (K > choose(views, max_number_modalities_per_cluster)){
print("Error: chose too many clusters")
return()
}
start_index <- cumsum(c(1, p))[1:views]
stop_index <- cumsum(p)
mu <- matrix(rnorm(K * views, 2, 10),
views, K)
sum_p = sum(p)
loadings <- matrix(0, sum_p, ncol=K)
GT_participation <- list()
GT_variables <- list()
for (k in 1:K){
### select subset of modalities to be involved in the cluster
subset_modalities = sort(sample(1:views, size=max_number_modalities_per_cluster))
#print(c(k, subset_modalities))
is_in_list <- any(sapply(GT_participation, function(x) all(x == subset_modalities)))
while(is_in_list){
#print("here")
subset_modalities = sort(sample(1:views, size=max_number_modalities_per_cluster))
is_in_list <- any(sapply(GT_participation, function(x) all(x == subset_modalities)))
}
GT_participation[[k]] <- subset_modalities
GT_variables[[k]] <- list()
for (m in subset_modalities){
if (is.null(s_m)){
loadings[start_index[m]: stop_index[m],k] = rnorm(n=p[m], mean=mu[m, k], sd=0.1)
GT_variables[[k]] <- c(GT_variables[[k]], start_index[m]: stop_index[m] )
}else{
index = sample(start_index[m]: stop_index[m], size=s_m, replace=FALSE)
GT_variables[[k]] <- c(GT_variables[[k]], index)
loadings[index,k] = rnorm(n=s_m, mean=mu[m, k], sd=0.1)
}
}
}
new_K = K
if (just_joint == FALSE){
### add some lone cluster
subset_modalities = sample(1:m, floor(K/2))
new_K = K + floor(K/2)
a = 1
for (m in subset_modalities){
GT_participation[[K + a]] <- c(m)
if (is.null(s_m)){
loadings[start_index[m]: stop_index[m],k] = rnorm(n=p[m], mean= 2, sd=0.1)
GT_variables[[a  + K]] <- start_index[m]: stop_index[m]
}else{
index = sample(start_index[m]: stop_index[m], size=s_m, replace=FALSE)
GT_variables[[a + K]] <- index
loadings[index, K + a] = rnorm(n=s_m, mean=2, sd=0.1)
}
a = a  + 1
}
}
score = matrix(0, nrow=new_K, ncol=n)
cluster = sapply(1:n, function(x){sample(1:new_K, 1)})
score[cbind(cluster, 1:n)] <- 1
means <- t(loadings %*% score)
# Generate mat_1 with random values from a normal distribution
##### Change here to make sure that it is compatible with different data types.
mat <- matrix(rnorm(length(means),
mean = as.vector(means), sd = sd),
nrow = n,
ncol = sum_p)
mat
library("devtools")
devtools::install_github("linnykos/tiltedCCA")
seed =10
p
X1 <- X[,1:100]
X = mat; X1 <- X[,1:100]
X2 <- X[,101:200]
TiltedCCAobject <- tiltedCCA::create_multiSVD(mat_1 = X1, mat_2 = X2,
dims_1 = 1:2, dims_2 = 1:2,
center_1 = F, center_2 = F,
normalize_row = T,
normalize_singular_value = F,
recenter_1 = F, recenter_2 = F,
rescale_1 = F, rescale_2 = F,
scale_1 = F, scale_2 = F)
clustering_1 <- factor(rep(1, n))
clustering_2 <- factor(rep(1, n))
clustering_1
TiltedCCAobject <- tiltedCCA::form_metacells(input_obj = TiltedCCAobject,
large_clustering_1 = clustering_1,
large_clustering_2 = clustering_2,
num_metacells = NULL)
TiltedCCAobject <- tiltedCCA::compute_snns(input_obj = TiltedCCAobject,
latent_k = 3,
num_neigh = 10,
bool_cosine = T,
bool_intersect = T,
min_deg = 1)
TiltedCCAobject <- tiltedCCA::fine_tuning(input_obj = TiltedCCAobject,
verbose = 0)
TiltedCCAobject <- tiltedCCA::compute_snns(input_obj = TiltedCCAobject,
latent_k = 3,
num_neigh = 10,
bool_cosine = T,
bool_intersect = T,
min_deg = 1)
install.packages("irlba")
install.packages("irlba")
TiltedCCAobject <- tiltedCCA::compute_snns(input_obj = TiltedCCAobject,
latent_k = 3,
num_neigh = 10,
bool_cosine = T,
bool_intersect = T,
min_deg = 1)
TiltedCCAobject <- tiltedCCA::tiltedCCA(input_obj = TiltedCCAobject)
TiltedCCAobject <- tiltedCCA::fine_tuning(input_obj = TiltedCCAobject,
verbose = 0)
TiltedCCAobject <- tiltedCCA::tiltedCCA_decomposition(TiltedCCAobject)
TiltedCCAobject
TiltedCCAobject$common_mat_1
dim(TiltedCCAobject$common_mat_1)
dim(TiltedCCAobject$common_mat_2)
dim(TiltedCCAobject$svd_1)
TiltedCCAobject$svd_1
help(prcomp)
pcaX <- prcomp(X)
pcaX$x
joint_info
dim(pcaX$x)
help(tiltedCCA::tiltedCCA)
?tiltedCCA::tiltedCCA
help(tiltedCCA::compute_snns)
?tiltedCCA::compute_snns
TiltedCCAobject$common_mat_1
dim(TiltedCCAobject$common_mat_1)
dim(TiltedCCAobject$common_mat_2)
pcaX$rotation
dim(pcaX$rotation)
install.packages("r.jive")
library(r.jive)
results_jive <- jive(X)
data(SimData)
results_jive <- jive(list(Data1 = X1,
Data2 = X2))
results_jive
results_jive$joint
results_jive$joint
results_jive$individual
dim(results_jive$individual)
dim(results_jive$individual)
(results_jive$individual)
BiocManager::install("MOFA2")
views = lapply(1:m, function(i){
return(X[, start_index[i]: stop_index[i]])
}),
views = lapply(1:m, function(i){
return(X[, start_index[i]: stop_index[i]])
})
views[[1]]
dim(views[[1]])
dim(views[[2]])
dim(views[[3]])
if (method_name == "MOFA"){
library(data.table)
library(MOFA2)
model_opts <- get_default_model_options(MOFAobject)
MOFAobject <- prepare_mofa(
object = MOFAobject,
data_options = data_opts,
model_options = model_opts,
training_options = train_opts
)
outfile = file.path(getwd(),"model.hdf5")
MOFAobject.trained <- run_mofa(MOFAobject, outfile)
}
library(data.table)
library(MOFA2)
n_views = 2;
n_samples = 200;
n_features = 1000;
n_factors = 10
data <- make_example_data(
n_views = n_views,
n_samples = n_samples,
n_features = n_features,
n_factors = n_factors
)[[1]]
View(mat_1)
data
data <- make_example_data(
n_views = n_views,
n_samples = n_samples,
n_features = n_features,
n_factors = n_factors
)
data <- make_example_data(
n_views = n_views,
n_samples = n_samples,
n_features = n_features,
n_factors = n_factors
)[[1]]
library(MOFA2)
help(create_mofa)
MOFAobject <- create_mofa(X1, X2, X3)
MOFAobject <- create_mofa(list(X1, X2, X3))
X3 = X[, 201:300]
MOFAobject <- create_mofa(list(X1, X2, X3))
MOFAobject
MOFAobject <- create_mofa(list(t(X1), t(X2), t(X3)))
MOFAobject
data_opts <- get_default_data_options(MOFAobject)
data_opts
model_opts <- get_default_model_options(MOFAobject)
MOFAobject <- prepare_mofa(
object = MOFAobject,
data_options = data_opts,
model_options = model_opts,
training_options = train_opts
)
train_opts <- get_default_training_options(MOFAobject)
MOFAobject <- prepare_mofa(
object = MOFAobject,
data_options = data_opts,
model_options = model_opts,
training_options = train_opts
)
outfile = file.path(getwd(),"model.hdf5")
MOFAobject.trained <- run_mofa(MOFAobject, outfile)
BiocManager::install("basilisk")
l
#BiocManager::install("basilisk")
#BiocManager::install("MOFA2")
library(data.table)
library(MOFA2)
MOFAobject.trained <- run_mofa(MOFAobject, outfile)
MOFAobject.trained <- run_mofa(MOFAobject, outfile, use_basilisk = TRUE )
library(scDesign3)
BiocManager::install("scDesign3")
library(scDesign3)
install.packages("BiocManager")
BiocManager::install("scDesign3")
install.packages(c("hardhat", "httr2", "loo", "pkgdown", "posterior", "RcppArmadillo", "reactR", "recipes", "reticulate", "StanHeaders"))
install.packages(c("hardhat", "httr2", "loo", "pkgdown", "posterior", "RcppArmadillo", "reactR", "recipes", "reticulate", "StanHeaders"))
install.packages(c("hardhat", "httr2", "loo", "pkgdown", "posterior", "RcppArmadillo", "reactR", "recipes", "reticulate", "StanHeaders"))
source("~/Documents/tensor-topic-modeling/market_basket_many_K.R", echo=TRUE)
K3=2
M = median(apply(D3, 2, sum))
debugSource("~/Documents/tensor-topic-modeling/algorithm.R", echo=TRUE)
method ="TTM-HOOI"
results <- run_method(data, K1=K1, K2=K2, K3=K3, M=M,
method=method)
X=t(D3)
sum(X[1,])
doc_length
x_train[1,]
sum(x_train[1,])
x_train[1,]
sum(x_train[1,])
active_words
length(active_words)
R
dim(X)
length(doc_length)
x_train = t(diag(1/ doc_length) %*% X[, active_words])
sum(x_train[1,])
sum(x_train[,1])
R <- length(active_words)
X_train <- tensorization(as.matrix(x_train), 3, Q1, Q2, R)
sum(X_train[1,1,])
sum(X_train@data[1,1,])
data <- list(D = D_new,
X =  X_train)
tmp<- score(data$X, normalization="TTM", method = "HOSVD", K1=K1, K2=K2, K3=K3, M=M,
as.sparse = FALSE)
